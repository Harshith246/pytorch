{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting torch\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/9b/a241f6e3d1df013e65e0b03b17e46bd9517036cd9ba9d8cb9384df396e3b/torch-1.1.0-cp35-cp35m-manylinux1_x86_64.whl (676.9MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 676.9MB 80kB/s  eta 0:00:01 0% |\u258f                               | 4.1MB 78.3MB/s eta 0:00:09    19% |\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 131.6MB 76.6MB/s eta 0:00:08    29% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                      | 201.5MB 78.9MB/s eta 0:00:07    32% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                     | 218.4MB 78.3MB/s eta 0:00:06    39% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                   | 267.9MB 77.1MB/s eta 0:00:06    55% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a              | 375.2MB 76.4MB/s eta 0:00:04\ufffd\ufffd\u2588\u258b            | 414.9MB 78.7MB/s eta 0:00:04\ufffd\u2588\u2588\u2588\u2588            | 423.3MB 80.3MB/s eta 0:00:04    64% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589           | 439.8MB 78.0MB/s eta 0:00:04|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588           | 443.6MB 78.5MB/s eta 0:00:03\ufffd\u2588\u2588\u2588\u258d          | 452.3MB 75.8MB/s eta 0:00:0370.0MB 78.2MB/s eta 0:00:03/s eta 0:00:03       | 478.3MB 75.9MB/s eta 0:00:03\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589         | 482.0MB 81.5MB/s eta 0:00:03      | 485.7MB 77.2MB/s eta 0:00:03\u258f        | 489.6MB 78.7MB/s eta 0:00:03\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 494.4MB 76.0MB/s eta 0:00:03\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b        | 498.3MB 75.4MB/s eta 0:00:03ta 0:00:03\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588        | 506.1MB 78.4MB/s eta 0:00:03/s eta 0:00:03\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u258e       | 513.5MB 74.8MB/s eta 0:00:03\ufffd\ufffd\u2588\u258f      | 531.4MB 73.9MB/s eta 0:00:02:00:02\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b      | 541.3MB 77.2MB/s eta 0:00:02:0200:02\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u258b     | 562.0MB 76.6MB/s eta 0:00:02\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a     | 564.9MB 77.5MB/s eta 0:00:02\u2588\u2588\u2588\u2588\u2589     | 568.7MB 76.4MB/s eta 0:00:02[K    84% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588     | 571.7MB 77.9MB/s eta 0:00:02\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f    | 575.0MB 76.3MB/s eta 0:00:02\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e    | 577.7MB 76.3MB/s eta 0:00:02\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c    | 580.7MB 66.5MB/s eta 0:00:020:00:02\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589    | 588.3MB 75.4MB/s eta 0:00:02\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588    | 591.2MB 76.5MB/s eta 0:00:02.8MB/s eta 0:00:02\ufffd\ufffd   | 596.8MB 76.9MB/s eta 0:00:02\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 600.2MB 75.2MB/s eta 0:00:02 0:00:01:01\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 615.6MB 57.3MB/s eta 0:00:02\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 618.1MB 76.1MB/s eta 0:00:01\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 620.5MB 77.8MB/s eta 0:00:01\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 623.1MB 78.4MB/s eta 0:00:01\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 625.8MB 75.4MB/s eta 0:00:01\u2588\u2588\u2588\u2588\u2588\u258a  | 628.2MB 77.9MB/s eta 0:00:01B/s eta 0:00:01.9MB 76.0MB/s eta 0:00:01\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 636.7MB 74.8MB/s eta 0:00:01\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 641.7MB 77.9MB/s eta 0:00:01 79.7MB/s eta 0:00:01\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 647.4MB 76.0MB/s eta 0:00:01 74.9MB/s eta 0:00:01\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 652.7MB 75.9MB/s eta 0:00:01\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 655.9MB 74.0MB/s eta 0:00:01\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 659.0MB 76.8MB/s eta 0:00:01\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 661.3MB 58.4MB/s eta 0:00:018% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 663.5MB 78.1MB/s eta 0:00:014MB 75.2MB/s eta 0:00:01[K    98% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 668.4MB 56.2MB/s eta 0:00:01\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 670.5MB 54.9MB/s eta 0:00:01[K    99% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 672.6MB 76.1MB/s eta 0:00:01\n\u001b[?25hCollecting torchvision\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/e9/76f3746e92e473d681b844d6d8d7485f6339a0933557fa6c8353b7864cc0/torchvision-0.3.0-cp35-cp35m-manylinux1_x86_64.whl (2.6MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.6MB 22.2MB/s ta 0:00:01\ufffd                            | 276kB 40.0MB/s eta 0:00:01\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e      | 2.0MB 82.6MB/s eta 0:00:01\n\u001b[?25hCollecting torchsummary\n  Downloading https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl\nRequirement already satisfied: numpy in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from torch) (1.13.3)\nRequirement already satisfied: six in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from torchvision) (1.11.0)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from torchvision) (4.2.1)\nRequirement already satisfied: olefile in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pillow>=4.1.1->torchvision) (0.44)\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\nInstalling collected packages: torch, torchvision, torchsummary\nSuccessfully installed torch-1.1.0 torchsummary-1.5.1 torchvision-0.3.0\n"
                }
            ], 
            "source": "!pip install torch torchvision torchsummary"
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import torch\nimport torch.nn as nn\n\nfrom torchvision.datasets import MNIST\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom torchsummary import summary\n\n"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "0it [00:00, ?it/s]"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "9920512it [00:00, 12243286.93it/s]                           \n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "0it [00:00, ?it/s]"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "32768it [00:00, 125129.35it/s]           \n0it [00:00, ?it/s]"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "1654784it [00:01, 1479292.78it/s]                           \n8192it [00:00, 71376.84it/s]            \n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\nExtracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz\nProcessing...\nDone!\n"
                }
            ], 
            "source": "\ntrain = MNIST('data', train=True, transform=transforms.ToTensor(), download=True)\ntest = MNIST('data', train=False, transform=transforms.ToTensor())"
        }, 
        {
            "source": "### Batch Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "train_loader = torch.utils.data.DataLoader(train, batch_size=128) \ntest_loader = torch.utils.data.DataLoader(test, batch_size=128)"
        }, 
        {
            "source": "###  Design neural Network aarchitecture", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "n_input = 784\nn_dense_1 = 64\nn_dense_2 = 64\nn_dense_3 = 64\nn_out = 10"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model = nn.Sequential(\n    \n    # first hidden layer: \n    nn.Linear(n_input, n_dense_1), \n    nn.ReLU(), \n    \n    # second hidden layer: \n    nn.Linear(n_dense_1, n_dense_2), \n    nn.ReLU(), \n    \n    # third hidden layer: \n    nn.Linear(n_dense_2, n_dense_3), \n    nn.ReLU(), \n    nn.Dropout(),  \n    \n    # output layer: \n    nn.Linear(n_dense_3, n_out) \n)"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Linear-1                [-1, 1, 64]          50,240\n              ReLU-2                [-1, 1, 64]               0\n            Linear-3                [-1, 1, 64]           4,160\n              ReLU-4                [-1, 1, 64]               0\n            Linear-5                [-1, 1, 64]           4,160\n              ReLU-6                [-1, 1, 64]               0\n           Dropout-7                [-1, 1, 64]               0\n            Linear-8                [-1, 1, 10]             650\n================================================================\nTotal params: 59,210\nTrainable params: 59,210\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.23\nEstimated Total Size (MB): 0.23\n----------------------------------------------------------------\n"
                }
            ], 
            "source": "summary(model, (1, n_input))"
        }, 
        {
            "source": "### Configure Training parameters", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cost_fxn = nn.CrossEntropyLoss() # includes softmax activation"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "optimizer = torch.optim.Adam(model.parameters())"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# for i in range(len(train)):\n#     print ('size of image{} label{}'.format(train[i][0].size(),train[i][1]))\n#     if i>4: break"
        }, 
        {
            "source": "###  Displaying an image", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fec1c07ae48>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "train_image, train_target = train[0]\nplt.imshow(train_image[0].numpy().squeeze(), cmap='gray_r');"
        }, 
        {
            "source": "### lets display more images ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# figure = plt.figure()\n# num_of_images = 60\n# for index in range(1, num_of_images +1):\n#     plt.subplot(6, 10, index)\n#     plt.axis('off')\n#     plt.imshow(train_image[index].numpy().squeeze(), cmap='gray_r')"
        }, 
        {
            "source": "### Train the model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 44, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def accuracy_pct(pred_y, true_y):\n  _, prediction = torch.max(pred_y, 1) # returns maximum values, indices; fed tensor, dim to reduce\n  correct = (prediction == true_y).sum().item()\n  return (correct / true_y.shape[0]) * 100.0"
        }, 
        {
            "execution_count": 45, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 45, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "469"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "n_batches = len(train_loader)\nn_batches"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "n_epochs = 10 \n\nprint('Training for {} epochs. \\n'.format(n_epochs))\n\nfor epoch in range(n_epochs):\n  \n  avg_cost = 0.0\n  avg_accuracy = 0.0\n  \n  for i, (X, y) in enumerate(train_loader): # enumerate() provides count of iterations  \n    \n    # forward propagation:\n    X_flat = X.view(X.shape[0], -1)\n    y_hat = model(X_flat)\n    cost = cost_fxn(y_hat, y)\n    avg_cost += cost / n_batches\n    \n    # backprop and optimization via gradient descent: \n    optimizer.zero_grad() # set gradients to zero; .backward() accumulates them in buffers\n    cost.backward()\n    optimizer.step()\n    \n    # calculate accuracy metric:\n    accuracy = accuracy_pct(y_hat, y)\n    avg_accuracy += accuracy / n_batches\n        \n    if (i + 1) % 100 == 0:\n      print('Step {}'.format(i + 1))\n    \n  print('Epoch {}/{} complete: Cost: {:.3f}, Accuracy: {:.1f}% \\n'\n        .format(epoch + 1, n_epochs, avg_cost, avg_accuracy)) \n  # TO DO: add test metrics\n\nprint('Training complete.')"
        }, 
        {
            "execution_count": 47, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 47, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "79"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "\n\nn_test_batches = len(test_loader)\nn_test_batches\n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model.eval() # disables dropout and batch norm\n\nwith torch.no_grad(): # disables autograd, reducing memory consumption\n  \n  avg_test_cost = 0.0\n  avg_test_acc = 0.0\n  \n  for X, y in test_loader:\n    \n    # make predictions: \n    X_flat = X.view(X.shape[0], -1)\n    y_hat = model(X_flat)\n    \n    # calculate cost: \n    cost = cost_fxn(y_hat, y)\n    avg_test_cost += cost / n_test_batches\n    \n    # calculate accuracy:\n    test_accuracy = accuracy_pct(y_hat, y)\n    avg_test_acc += test_accuracy / n_test_batches\n\nprint('Test cost: {:.3f}, Test accuracy: {:.1f}%'.format(avg_test_cost, avg_test_acc))\n\n# model.train() # 'undoes' model.eval()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}